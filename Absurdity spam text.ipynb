{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83b8d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import printable\n",
    "from nltk.tokenize import word_tokenize\n",
    "from autocorrect import Speller\n",
    "import re\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import logging\n",
    "from urlextract import URLExtract\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pytesseract\n",
    "import wordninja\n",
    "from collections import Counter\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "with open('config.json') as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "# MONGO_USERNAME = secrets[\"MONGO_USERNAME\"]\n",
    "# MONGO_PASSWORD = secrets[\"MONGO_PASSWORD\"]\n",
    "# MONGO_HOST = secrets[\"MONGO_HOST\"]\n",
    "# MONGO_PORT = secrets[\"MONGO_PORT\"]\n",
    "# MONGO_DB = secrets[\"MONGO_DB_NAME\"]\n",
    "\n",
    "# Client = MongoClient(\n",
    "#     host=MONGO_HOST,\n",
    "#     port=MONGO_PORT,\n",
    "#     username=MONGO_USERNAME,\n",
    "#     password=MONGO_PASSWORD,\n",
    "#     authSource=\"admin\",\n",
    "#     authMechanism=\"SCRAM-SHA-1\"\n",
    "# )\n",
    "\n",
    "Client = MongoClient(secrets['mongodbConnectionURI'])\n",
    "\n",
    "db = Client.get_default_database()\n",
    "\n",
    "corp = db.corpus\n",
    "spam_words_collection = db.spam_words\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "              'v', 'w', 'x', 'y', 'z', 'an', 'll', 've', 're', 'ma']\n",
    "greeting_words = ['hi', 'hey', 'hello', 'hey there', 'hi everyone', 'hello there', 'hi there', 'hey everyone',\n",
    "                  'hey all']\n",
    "\n",
    "CS_WHITELISTED_COMMENTS = [\n",
    "    \"Hey! Our Beauty Advisors can help you with your concern. Connect with our experts under the personalized beauty advise banner on the MyGlamm app (Monday to Sunday | 10 am to 7 pm) to get a personalized advice.\",\n",
    "    \"Hey! Our Customer care team can help with your concern. Please drop an email on hello@myglamm.com or connect with us on Chat option available in Help & Support. We are available between Monday to Sunday (10 am to 7 pm).\"\n",
    "]\n",
    "\n",
    "\n",
    "def demoji(string):\n",
    "    '''\n",
    "    Removing emojis present in a text\n",
    "    '''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r' ', string)\n",
    "\n",
    "\n",
    "def demoticon(text):\n",
    "    '''\n",
    "    Removing demoticons present in a text\n",
    "    '''\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r' ', text)\n",
    "\n",
    "\n",
    "def deurls(text):\n",
    "    '''\n",
    "    Removing URLs present in a text\n",
    "    '''\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r' ', text)\n",
    "\n",
    "\n",
    "def utils(text):\n",
    "    '''\n",
    "    1. converting text to lower case\n",
    "    2. removing punctuations and special characters\n",
    "    3. removing numbers\n",
    "    4. tokenizing the entire text\n",
    "    5. removing duplicate words\n",
    "    6. removing stop words\n",
    "    6. lemmatizing each word in tokenized list\n",
    "    '''\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub('[^A-Z a-z]+', ' ', text)\n",
    "    text = ' '.join(dict.fromkeys(text.split()))\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    return utils(demoji(demoticon(deurls(text))))\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text_list = word_tokenize(text)\n",
    "    text_list = [lemmatizer.lemmatize(w) for w in text_list]\n",
    "    text_list = [w for w in text_list if not w in stop_words]\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def valid_whitelisted_comments(post):\n",
    "    '''\n",
    "       check if the post has a prefix text with is present in prefix_text_array then return true\n",
    "    '''\n",
    "    for whitelisted_comments in CS_WHITELISTED_COMMENTS:\n",
    "        if whitelisted_comments.lower() == post.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def spam_word_in_spam_array(post):\n",
    "    post_array = list(map(lambda x: x.lower(), post.split()))\n",
    "    spam_words_list = list(spam_words_collection.distinct('word'))\n",
    "    for word in post_array:\n",
    "        for spam_word in spam_words_list:\n",
    "            if spam_word in word:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c02241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post= \"asdf qwerty zxcv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9254369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam_word_in_spam_array(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbec4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_array = list(map(lambda x: x.lower(), post.split()))\n",
    "post_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4738653",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words_collection.count_documents({'word': {\"$in\": post_array}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ce792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word(word, subwords):\n",
    "    for subword in subwords:\n",
    "        if subword in word:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab51ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"apple\"\n",
    "subwords = [\"app\", \"le\"]\n",
    "result = check_word(word, subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff48b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxfuckcxxk\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c700b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+91',\n",
       " '9523700492',\n",
       " '9864583197',\n",
       " 'BDSM',\n",
       " 'Kill ourselves ',\n",
       " 'MYGLAM=CUSTOMER=CARE=NUMBER',\n",
       " 'UPI',\n",
       " 'aaa',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abused as a child',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'anal',\n",
       " 'are',\n",
       " 'ay',\n",
       " 'babri masjid',\n",
       " 'being harassed',\n",
       " 'bisexual',\n",
       " 'bj',\n",
       " 'blow job',\n",
       " 'blue film',\n",
       " 'boobs',\n",
       " 'bug',\n",
       " 'bullied',\n",
       " 'bullying me',\n",
       " 'call',\n",
       " 'can’t talk to anyone',\n",
       " 'chatty',\n",
       " 'child abuse',\n",
       " 'child porn',\n",
       " 'child porno',\n",
       " 'chink',\n",
       " 'chinky',\n",
       " 'choke',\n",
       " 'choked',\n",
       " 'clitoris',\n",
       " 'cock',\n",
       " 'contact',\n",
       " 'cr',\n",
       " 'credit',\n",
       " 'critical',\n",
       " 'crucial',\n",
       " 'cruel',\n",
       " 'customer',\n",
       " 'cut myself',\n",
       " 'cutting myself',\n",
       " 'death',\n",
       " 'debit',\n",
       " 'depressed',\n",
       " 'depression',\n",
       " 'dial',\n",
       " 'dick',\n",
       " 'die',\n",
       " 'dm me',\n",
       " 'dowry',\n",
       " 'ea',\n",
       " 'eae',\n",
       " 'ee',\n",
       " 'eel',\n",
       " 'emergency',\n",
       " 'emotional abuse',\n",
       " 'emotional torture',\n",
       " 'emotionally tortured',\n",
       " 'emotionally torturing',\n",
       " 'end my life',\n",
       " 'ending her life',\n",
       " 'ending his life',\n",
       " 'ending my life',\n",
       " 'eo',\n",
       " 'error',\n",
       " 'f.u.c.k.',\n",
       " 'fck',\n",
       " 'finger/fingering',\n",
       " 'fingering',\n",
       " 'follow me',\n",
       " 'forced marriage',\n",
       " 'forced me to marry',\n",
       " 'forced sex',\n",
       " 'forcing me to have sex',\n",
       " 'forcing sex',\n",
       " 'fraud',\n",
       " 'fuck',\n",
       " 'go',\n",
       " 'hang myself',\n",
       " 'hanged myself',\n",
       " 'hanging myself',\n",
       " 'harass',\n",
       " 'harassing',\n",
       " 'harassment',\n",
       " 'have anxiety',\n",
       " 'held',\n",
       " 'help center',\n",
       " 'help desk',\n",
       " 'help team',\n",
       " 'helpline',\n",
       " 'hindu',\n",
       " 'hit me',\n",
       " 'hitting me',\n",
       " 'horny',\n",
       " 'horoscope',\n",
       " 'horoscopes',\n",
       " 'hot',\n",
       " 'hurt me',\n",
       " 'hurt myself',\n",
       " 'hurting me',\n",
       " 'hurting myself',\n",
       " 'incest',\n",
       " 'incests',\n",
       " 'incestual',\n",
       " 'intimacy',\n",
       " 'islam',\n",
       " 'kill',\n",
       " 'kill her',\n",
       " 'kill him',\n",
       " 'kill myself',\n",
       " 'kill them',\n",
       " 'killed her',\n",
       " 'killed him',\n",
       " 'killed myself',\n",
       " 'killing her',\n",
       " 'killing him',\n",
       " 'killing myself',\n",
       " 'killing ourselves ',\n",
       " 'killing them',\n",
       " 'lesb',\n",
       " 'lesbian',\n",
       " 'lesbo',\n",
       " 'ley',\n",
       " 'lick',\n",
       " 'lonely',\n",
       " 'masjid',\n",
       " 'mastarbate',\n",
       " 'masterbate',\n",
       " 'masturbate',\n",
       " 'masturbates',\n",
       " 'mental abuse',\n",
       " 'mental torture',\n",
       " 'mentally tortured',\n",
       " 'mentally torturing',\n",
       " 'molest',\n",
       " 'molestation ',\n",
       " 'molested',\n",
       " 'molester',\n",
       " 'molesters',\n",
       " 'molesting',\n",
       " 'molests',\n",
       " 'mosque',\n",
       " 'mstrbte',\n",
       " 'murder',\n",
       " 'murdered',\n",
       " 'murdering',\n",
       " 'muslim',\n",
       " 'nee',\n",
       " 'nigga',\n",
       " 'nigger',\n",
       " 'nipple',\n",
       " 'nipples',\n",
       " 'nude',\n",
       " 'number',\n",
       " 'obe',\n",
       " 'oe',\n",
       " 'offerz.xyz',\n",
       " 'og',\n",
       " 'orgy',\n",
       " 'paced',\n",
       " 'pakistan',\n",
       " 'penis',\n",
       " 'phone',\n",
       " 'phone no',\n",
       " 'popxo',\n",
       " 'porn',\n",
       " 'pornography',\n",
       " 'pr',\n",
       " 'punch',\n",
       " 'punched',\n",
       " 'pussy',\n",
       " 'rape',\n",
       " 'raped',\n",
       " 'raper',\n",
       " 'rapes',\n",
       " 'raping',\n",
       " 'risk',\n",
       " 's.u.i.c.i.d.e.',\n",
       " 'scam',\n",
       " 'se',\n",
       " 'self harm',\n",
       " 'self harmed',\n",
       " 'self harming',\n",
       " 'semen',\n",
       " 'service no',\n",
       " 'sex',\n",
       " 'sext',\n",
       " 'sexting',\n",
       " 'sexual',\n",
       " 'sexual abuse',\n",
       " 'sexual abused',\n",
       " 'sexual harassment',\n",
       " 'sexually abusing',\n",
       " 'sexually harassed',\n",
       " 'sexually harassing',\n",
       " 'sexy',\n",
       " 'slap me',\n",
       " 'slapped me',\n",
       " 'slapping me',\n",
       " 'spam',\n",
       " 'sucide ',\n",
       " 'suck',\n",
       " 'suffocate',\n",
       " 'suffocated',\n",
       " 'suicidal',\n",
       " 'suicide',\n",
       " 'suicides',\n",
       " 'suiciding',\n",
       " 'support team',\n",
       " 'te',\n",
       " 'teen',\n",
       " 'telephone',\n",
       " 'terrorist',\n",
       " 'testspam',\n",
       " 'threesome',\n",
       " 'toll free',\n",
       " 'torture me',\n",
       " 'tortured me',\n",
       " 'torturing her ',\n",
       " 'torturing him',\n",
       " 'torturing me',\n",
       " 'touched me incorrectly',\n",
       " 'ue',\n",
       " 'underage',\n",
       " 'unmarried',\n",
       " 'urgent',\n",
       " 'vagina',\n",
       " 'vegina',\n",
       " 'victim',\n",
       " 'violence',\n",
       " 'violent',\n",
       " 'virgin',\n",
       " 'winkl',\n",
       " 'winkle',\n",
       " '⑨⑤②③⑦⓪⓪④⑨②',\n",
       " '➒➎➋➌➐⓿⓿➍➒➋',\n",
       " '𝟵𝟱𝟮𝟯𝟳𝟬𝟬𝟰𝟵𝟮']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(spam_words_collection.distinct('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_digits(post, printable_digits=2, digits=4, digit_letters=2):\n",
    "    if (len(set(post).difference(printable))) > printable_digits or len(re.findall('\\d', post)) > digits or \\\n",
    "            len(re.findall('(:zero:|:one:|:two:|:three:|:four:|:five:|:six:|:seven:|:eight:|:nine:)',\n",
    "                           post)) > digit_letters or \\\n",
    "            len(re.findall('(zero|one|two|three|four|five|six|seven|eight|nine)', post, re.IGNORECASE)) > digit_letters:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_emojis(post):\n",
    "    if isinstance(post, str):\n",
    "        try:\n",
    "            post = preprocess(post)\n",
    "        except:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_mentions(post):\n",
    "    post = re.sub(r\"@[\\da-z]{24}\\b\", \"\", post)\n",
    "    return post\n",
    "\n",
    "\n",
    "def remove_hashtags_ids(post):\n",
    "    post = re.sub(r\"#[\\da-z]{24}\\b\", \"\", post)\n",
    "    return post\n",
    "\n",
    "\n",
    "def remove_hashtags_comments(post):\n",
    "    post = \" \".join(filter(lambda x: x[0] != '#', post.split()))\n",
    "    return post\n",
    "\n",
    "\n",
    "def whitelisting_emojis(post):\n",
    "    emojis_pattern = re.compile(pattern=\"[\"\n",
    "                                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                        \"]+\", flags=re.UNICODE)\n",
    "    post = emojis_pattern.sub(r'', post)\n",
    "    return post\n",
    "\n",
    "\n",
    "# function to validate the hashtags in a post\n",
    "def validate_hashtags_comments(post):\n",
    "    post = remove_hashtags_ids(post)\n",
    "    # initializing hashtag_list variable\n",
    "    hashtag_list = []\n",
    "    # splitting the post into words\n",
    "    if len(post.split()) == 1:\n",
    "        for word in post.split('#'):\n",
    "            # checking the first character of every word\n",
    "            # adding the word to the hashtag_list\n",
    "            hashtag_list.append(word)\n",
    "    else:\n",
    "        for word in post.split():\n",
    "            # checking the first character of every word\n",
    "            if word[0] == '#':\n",
    "                # adding the word to the hashtag_list\n",
    "                hashtag_list.append(word[1:])\n",
    "\n",
    "    hashtag_list = list(filter(None, hashtag_list))\n",
    "    # print(\"Hashtags: \",hashtag_list)\n",
    "    validation_list = []\n",
    "    for j in range(0, len(hashtag_list)):\n",
    "        items = hashtag_list[j]\n",
    "        if spam_word_in_spam_array(items) == True and check_digits(items, printable_digits=6, digits=6,\n",
    "                                                                   digit_letters=6) == True and check_emojis(\n",
    "                items) == True:\n",
    "            validation_list.append(1)\n",
    "        else:\n",
    "            validation_list.append(0)\n",
    "    if all(validation_list) == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def basic_text_check(post):\n",
    "    if not spam_word_in_spam_array(post):\n",
    "        return False\n",
    "\n",
    "    if not check_digits(post, printable_digits=6, digits=6, digit_letters=6):\n",
    "        return False\n",
    "\n",
    "    if not check_emojis(post):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def rotate_image_manualy(imgGray):\n",
    "    rtext=''\n",
    "    for i in range(0,360,15):\n",
    "        rotated_image = imgGray.rotate(i)\n",
    "        txt = pytesseract.image_to_string(rotated_image)\n",
    "        rtext+=txt\n",
    "    return rtext\n",
    "\n",
    "def cleaned_text(image_text):\n",
    "    cleaned_text = wordninja.split(image_text)\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    #cleaned_text = \" \".join(w for w in nltk.wordpunct_tokenize(cleaned_text) if w.lower() in set(nltk.corpus.words.words()) or not w.isalpha())\n",
    "    cleaned_text = ' '.join( [w for w in cleaned_text.split() if len(w) >1] )\n",
    "    cleaned_text = cleaned_text.split(\" \")\n",
    "    cleaned_text = Counter(cleaned_text)\n",
    "    cleaned_text = \" \".join(cleaned_text.keys())\n",
    "    return cleaned_text\n",
    "\n",
    "def check_image_absurdity(url, user_id):\n",
    "    from app import whitelist_userIDs_col\n",
    "    try:\n",
    "        logging.info(\"Read image from url: \"+url)\n",
    "        image = requests.get(url, stream=True, timeout=1).raw\n",
    "        image = Image.open(image)\n",
    "        imgGray = image.convert('L')\n",
    "        image_text = pytesseract.image_to_string(imgGray).replace(\"\\n\", \"\")\n",
    "        image_text = cleaned_text(image_text)\n",
    "        logging.info(\"Initial pytesseract text_detection: \" + str(image_text))\n",
    "        if len(image_text) > 0 and not basic_text_check(image_text):\n",
    "            logging.info(\"pytesseract  basic_text_check- Image is Invalid : \" + str(image_text))\n",
    "            return False\n",
    "        elif len(image_text) > 0 and image_text.replace(' ','').isdigit():\n",
    "            logging.info(\"pytesseract  isdigit- Image is Invalid : \" + str(image_text))\n",
    "            return False\n",
    "        elif len(image_text) > 0 and basic_text_check(image_text):\n",
    "            logging.info(\"pytesseract  basic_text_check- Image is valid : \" + str(image_text))\n",
    "            return True\n",
    "        elif len(image_text) == 0:\n",
    "            image_text = rotate_image_manualy(imgGray)\n",
    "            logging.info(\"rotate_image_manualy image_text: \"+image_text)\n",
    "            image_text = cleaned_text(image_text)\n",
    "            logging.info(\"cleaned_text image_text: \"+image_text)\n",
    "            if len(image_text) > 0 and not basic_text_check(image_text):\n",
    "                logging.info(\"rotate_image_manualy  basic_text_check- Image is Invalid : \" + str(image_text))\n",
    "                return False\n",
    "            elif len(image_text) > 0 and image_text.replace(' ','').isdigit():\n",
    "                logging.info(\"rotate_image_manualy  isdigit- Image is Invalid : \" + str(image_text))\n",
    "                return False\n",
    "            elif len(image_text) > 0 and basic_text_check(image_text):\n",
    "                logging.info(\"rotate_image_manualy  basic_text_check- Image is valid : \" + str(image_text))\n",
    "                return True \n",
    "            elif len(image_text) == 0:\n",
    "                try:\n",
    "                    user_id_data = whitelist_userIDs_col.find_one({'userID': user_id})\n",
    "                    if user_id_data and user_id_data.get('userID') and (user_id_data.get('whiteListed') == \"True\"\n",
    "                                                                        or user_id_data.get('whiteListed')):\n",
    "                        return True\n",
    "                    logging.info(\"  user valiadtion - Image is Invalid : \" + str(image_text))\n",
    "                    return False\n",
    "                except Exception as e:\n",
    "                    logging.info(\"user validation failed for image text : \" + str(image_text)+ \"and image url: \"+str(url)+\" and Exception: \"+str(e))\n",
    "                    return False\n",
    "        else:\n",
    "            logging.info(\"  - Image is Valid : \" + str(image_text))\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logging.error(\"Image Validation Failed : \" + str(e))\n",
    "        return False\n",
    "\n",
    "\n",
    "def classify(post):\n",
    "    # Main classification function\n",
    "\n",
    "    '''\n",
    "    True: Non-Spam\n",
    "    False: Spam\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Logic 1: If post text is string type, then it preprocessing is applied to the entire post text\n",
    "             otherwise it is marked as spam\n",
    "\n",
    "    '''\n",
    "\n",
    "    # identifying hashtag comments and validating them:\n",
    "    if \"#\" in post:\n",
    "        if validate_hashtags_comments(post) == True:\n",
    "            post = remove_hashtags_comments(post)\n",
    "            post = remove_hashtags_ids(post)\n",
    "        else:\n",
    "            logging.info(\"Invalid Hashtags in post: \" + str(post))\n",
    "            return False\n",
    "\n",
    "    urls = URLExtract().find_urls(post)\n",
    "    if len(urls) > 0:\n",
    "        if len(post.split()) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            for url in urls:\n",
    "                post = post.replace(url, '')\n",
    "\n",
    "    post = remove_mentions(post)\n",
    "\n",
    "    if len(post.strip()) > 0:\n",
    "        # whitelisting important emojis\n",
    "        post = whitelisting_emojis(post)\n",
    "\n",
    "        if valid_whitelisted_comments(post):\n",
    "            logging.info(\"Valid Post: \" + str(post))\n",
    "            return True\n",
    "\n",
    "        correct_text = spell(post)\n",
    "        if correct_text in greeting_words:\n",
    "            logging.info(\"Greeting words in Post: \" + str(post))\n",
    "            return False\n",
    "\n",
    "        if basic_text_check(post):\n",
    "            logging.info(\"Valid Post: \" + str(post))\n",
    "            return True\n",
    "        else:\n",
    "            logging.info(\"Failed basic check for post: \" + str(post))\n",
    "            return False\n",
    "    else:\n",
    "        logging.info(\"Valid Post: \" + str(post))\n",
    "        return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
